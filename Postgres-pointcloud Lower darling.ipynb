{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Querying  1 775 965 000 points with postgres-pointcloud\n",
    "\n",
    "442 tiles, ~1.7 billion points.\n",
    "\n",
    "What do we want to do?\n",
    "- test point query timing\n",
    "- select some tiles which contain a lot of trees\n",
    "- see how LandSAT and LiDAR tree cover data match up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import psycopg2 as ppg\n",
    "import numpy as np\n",
    "import ast\n",
    "from osgeo import ogr\n",
    "\n",
    "import shapely as sp\n",
    "from shapely.geometry import Point,Polygon,asShape\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "from shapely import speedups\n",
    "\n",
    "\n",
    "import cartopy as cp\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pdsql\n",
    "\n",
    "import geopandas as gp\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import fiona\n",
    "\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speedups.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speedups.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a postgres connection with psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  PGPASSWORD=pointy_cloudy psql -h localhost -d pcbm_pc -U pcbm\n",
    "pg_connection = \"dbname=pcbm_pc user=pcbm password=pointy_cloudy host=130.56.244.246\"\n",
    "conn = ppg.connect(pg_connection)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First query for some blocks - this gets them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbox_query = 'SELECT ST_Extent(pa)::geometry(Polygon, 28355) as table_extent FROM ga_ld_pc;'\n",
    "\n",
    "%time bbox = gp.read_postgis(bbox_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#blocks_query = \"SELECT pa::geometry(Polygon, 28355) AS geom, PC_PatchAvg(pa, 'Z') AS elevation, id FROM act_patches;\"\n",
    "\n",
    "#blocks_query = \"SELECT st_astext(PC_envelope(pa)::geometry(Polygon, 28355)) AS geom, PC_PatchAvg(pa, 'Z') AS elevation, id FROM ga_ld_pc;\"\n",
    "\n",
    "blocks_query = \"select PC_envelope(pa)::geometry(Polygon, 28355) AS geom, PC_PatchAvg(pa, 'Z') AS elevation from ga_ld_pc limit 1000;\"\n",
    "\n",
    "%time blocks = gp.read_postgis(blocks_query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how many rows (where a block of points is a row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polys = gp.GeoSeries(blocks.geom)\n",
    "patches = gp.GeoDataFrame({'geometry': polys, 'elevation': blocks.elevation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blocks_query = \"SELECT pa::geometry(Polygon, 28355) AS geom, PC_PatchAvg(pa, 'Z') AS elevation, id FROM ga_ld_pc where PC_PatchAvg(pa, 'Z') > 400;\"\n",
    "\n",
    "%time thepatches = gp.read_postgis(blocks_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thepatches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time highpatches = thepatches.query('elevation > 820')\n",
    "highpatches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's map the patches of data we collected - Black Mountain, above 820m high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highpatches.plot(column='elevation',colormap='BrBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now collect the points from the same region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points_query = \"with pts as(SELECT PC_Explode(pa) as pt FROM act_patches where PC_PatchAvg(pa, 'Z') > 820 ) select st_astext(pt::geometry) from pts;\"\n",
    "\n",
    "#get raw point data, not as a geometry\n",
    "#points_query =  \"SELECT PC_astext(PC_Explode(pa)) as pt FROM act_patches where PC_PatchAvg(pa, 'Z') > 700 ;\"\n",
    "\n",
    "%time pts = pdsql.read_sql(points_query, conn)\n",
    "\n",
    "# point storage schema:\n",
    "# 1 = intens, 2 = ReturnNo, 3 = Numreturns, 4 = scandirectionflag, 5 = edgeofflightline\n",
    "# 6 = classification (ASPRS), 7 = scananglerank, 8 = user data, 9 = pointsourceID\n",
    "# 10 = R, 11 = G, 12 = B, 13 = GPSTime, 14 = X, 15 = Y, 16 = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#how many points did we get?\n",
    "pts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#had to check the schema to find point order...\n",
    "schema_query =  \"SELECT * FROM pointcloud_formats where pcid = 4;\"\n",
    "\n",
    "schm = pdsql.read_sql(schema_query, conn)\n",
    "print(schm.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thepoints = []\n",
    "\n",
    "for point in pts.st_astext:\n",
    "    this = wkt_loads(point)\n",
    "    thepoints.append([this.x,this.y,this.z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thepoints = np.squeeze(thepoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(thepoints[:,0], thepoints[:,1], c = thepoints[:,2], lw=0, s=5, cmap='BrBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now make a pretty plot - points, patches in the subset, and all the patches in the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(25/2.51, 25/2.51)\n",
    "\n",
    "BLUE = '#6699cc'\n",
    "RED = '#cc6699'\n",
    "\n",
    "ax = fig.gca() \n",
    "ax.scatter(thepoints[:,0], thepoints[:,1], c = thepoints[:,2], lw=0, s=3, cmap='BrBG')\n",
    "for patch in thepatches.geom:\n",
    "    ax.add_patch(PolygonPatch(patch, fc=BLUE, ec=BLUE, alpha=0.2, zorder=2 ))\n",
    "    \n",
    "for patch in highpatches.geom:\n",
    "    ax.add_patch(PolygonPatch(patch, fc=BLUE, ec=RED, alpha=0.2, zorder=2 ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting points by classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ASPRS class 6 - buildings\n",
    "bldng_query = \"WITH filtered_patch AS (SELECT PC_FilterEquals(pa, 'Classification', 6) as f_patch FROM act_patches where PC_PatchAvg(pa, 'Z') > 820) SELECT st_astext(point::geometry) FROM filtered_patch, pc_explode(f_patch) AS point;\" \n",
    "%time bld_pts = pdsql.read_sql(bldng_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bld_pts.head()\n",
    "\n",
    "bldpoints = []\n",
    "\n",
    "for point in bld_pts.st_astext:\n",
    "    this = wkt_loads(point)\n",
    "    bldpoints.append([this.x,this.y,this.z])\n",
    "bldpoints = np.squeeze(bldpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ASPRS class 2 - ground\n",
    "grnd_query = \"WITH filtered_patch AS (SELECT PC_FilterEquals(pa, 'Classification', 2) as f_patch FROM act_patches where PC_PatchAvg(pa, 'Z') > 820) SELECT st_astext(point::geometry) FROM filtered_patch, pc_explode(f_patch) AS point;\" \n",
    "%time grnd_pts = pdsql.read_sql(grnd_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grnd_pts.head()\n",
    "\n",
    "grndpoints = []\n",
    "\n",
    "for point in grnd_pts.st_astext:\n",
    "    this = wkt_loads(point)\n",
    "    grndpoints.append([this.x,this.y,this.z])\n",
    "grndpoints = np.squeeze(grndpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ASPRS class 5 - high vegetation\n",
    "hv_query = \"WITH filtered_patch AS (SELECT PC_FilterEquals(pa, 'Classification', 5) as f_patch FROM ga_ld_pc where PC_PatchAvg(pa, 'Z') > 40) SELECT st_astext(point::geometry) FROM filtered_patch, pc_explode(f_patch) AS point;\" \n",
    "%time hv_pts = pdsql.read_sql(hv_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ASPRS class 5 - high vegetation\n",
    "hv_query = \"WITH filtered_patch AS (SELECT PC_FilterEquals(pa, 'Classification', 5) as f_patch FROM ga_ld_pc where PC_Intersection(pa, 'SRID=4326;POLYGON((-126.451 45.552, -126.42 47.55, -126.40 45.552, -126.451 45.552))'::geometry\n",
    ") SELECT st_astext(point::geometry) FROM filtered_patch, pc_explode(f_patch) AS point;\" \n",
    "%time hv_pts = pdsql.read_sql(hv_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv_pts.head()\n",
    "\n",
    "hvpoints = []\n",
    "\n",
    "for point in hv_pts.st_astext:\n",
    "    this = wkt_loads(point)\n",
    "    hvpoints.append([this.x,this.y,this.z])\n",
    "hvpoints = np.squeeze(hvpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(25/2.51, 25/2.51)\n",
    "\n",
    "BLUE = '#6699cc'\n",
    "RED = '#cc6699'\n",
    "\n",
    "ax = fig.gca() \n",
    "ax.scatter(grndpoints[:,0], grndpoints[:,1], c = grndpoints[:,2], lw=0, s=3, cmap='plasma')\n",
    "ax.scatter(bldpoints[:,0], bldpoints[:,1], c = bldpoints[:,2], lw=0, s=3, cmap='viridis')\n",
    "ax.scatter(hvpoints[:,0], hvpoints[:,1], c = hvpoints[:,2], lw=0, s=3, cmap='BrBG')\n",
    "\n",
    "for patch in thepatches.geom:\n",
    "    ax.add_patch(PolygonPatch(patch, fc=BLUE, ec=BLUE, alpha=0.2, zorder=2 ))\n",
    "    \n",
    "for patch in highpatches.geom:\n",
    "    ax.add_patch(PolygonPatch(patch, fc=BLUE, ec=RED, alpha=0.2, zorder=2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up for 3d plots\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pylab as pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt_az=300\n",
    "plt_elev = 50.\n",
    "plt_s = 2\n",
    "\n",
    "cb_fmt = '%.1f'\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(30/2.51, 25/2.51)\n",
    "\n",
    "ax0 = fig.add_subplot(111, projection='3d')\n",
    "ax0.scatter(grndpoints[:,0], grndpoints[:,1],grndpoints[:,2], c=np.ndarray.tolist(grndpoints[:,2]),\\\n",
    "                lw=0, s=plt_s, cmap='plasma')\n",
    "ax0.scatter(bldpoints[:,0], bldpoints[:,1],bldpoints[:,2], c=np.ndarray.tolist(bldpoints[:,2]),\\\n",
    "                lw=0, s=plt_s, cmap='viridis')\n",
    "ax0.scatter(hvpoints[:,0], hvpoints[:,1],hvpoints[:,2], c=np.ndarray.tolist(hvpoints[:,2]),\\\n",
    "                lw=0, s=plt_s-1, cmap='BrBG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to three.js?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import vtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('ground_points.txt', grndpoints, delimiter=',')\n",
    "np.savetxt('bld_points.txt', bldpoints, delimiter=',')\n",
    "np.savetxt('hv_points.txt', hvpoints, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "\n",
    "- too many things!\n",
    "- select from database by:\n",
    "    - class (demonstrated here)\n",
    "    - height above ground (need to integrate PDAL and PCL)\n",
    "    - tree cover\n",
    "    - intersection with objects\n",
    "- things on the list:\n",
    "    - comparing LandSAT bare ground and LIDAR bare ground\n",
    "    - tree heights and geophysical properties\n",
    "    - ...\n",
    "\n",
    "### All very cool but why?\n",
    "National elevation maps - storing and managing many billions of points as a coherent dataset for precise elevation estimation. Also aiming to store provenance - if there's a data issue, we need more than just points. We need to figure out why the issue occurred, and fix it. We can also store things like point accuracy, some QC metrics, whatever point attributes we like! Or points from manifold sources:\n",
    "- airborne LiDAR\n",
    "- terrestrial scanners\n",
    "- 3D photogrammetry\n",
    "- geophysical datasets (already as points in netCDF)\n",
    "- output of discrete element models (eg. Kool et al, or new sea ice models in development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
